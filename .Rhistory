}
extract_history <- function(history, bill_id) {
if (is.null(history)) return(NULL)
do.call(rbind, lapply(history, function(x) {
data.frame(
date = ifelse(is.null(x$date), NA, x$date),
action = ifelse(is.null(x$action), NA, x$action),
chamber = ifelse(is.null(x$chamber), NA, x$chamber),
importance = ifelse(is.null(x$importance), NA, x$importance),
stringsAsFactors = FALSE
)
}))
}
extract_sponsors <- function(sponsors, bill_id) {
if (is.null(sponsors)) return(NULL)
do.call(rbind, lapply(sponsors, function(x) {
data.frame(
bill_id = bill_id,
people_id = ifelse(is.null(x$people_id), NA, x$people_id),
party = ifelse(is.null(x$party), NA, x$party),
role = ifelse(is.null(x$role), NA, x$role),
name = ifelse(is.null(x$name), NA, x$name),
sponsor_order = ifelse(is.null(x$sponsor_order), NA, x$sponsor_order),
sponsor_type_id = ifelse(is.null(x$sponsor_type_id), NA, x$sponsor_type_id),
stringsAsFactors = FALSE
)
}))
}
extract_sasts <- function(sasts, bill_id) {
if (is.null(sasts)) return(NULL)
do.call(rbind, lapply(sasts, function(x) {
data.frame(
type = ifelse(is.null(x$type), NA, x$type),
sast_bill_number = ifelse(is.null(x$sast_bill_number), NA, x$sast_bill_number),
sast_bill_id = ifelse(is.null(x$sast_bill_id), NA, x$sast_bill_id),
stringsAsFactors = FALSE
)
}))
}
extract_texts <- function(texts, bill_id) {
if (is.null(texts)) return(NULL)
do.call(rbind, lapply(texts, function(x) {
data.frame(
date = ifelse(is.null(x$date), NA, x$date),
type = ifelse(is.null(x$type), NA, x$type),
type_id = ifelse(is.null(x$type_id), NA, x$type_id),
mime = ifelse(is.null(x$mime), NA, x$mime),
mime_id = ifelse(is.null(x$mime_id), NA, x$mime_id),
url = ifelse(is.null(x$url), NA, x$url),
state_link = ifelse(is.null(x$state_link), NA, x$state_link),
text_size = ifelse(is.null(x$text_size), NA, x$text_size),
stringsAsFactors = FALSE
)
}))
}
#######################################################################################
#Parses multiple JSON paths for bill data, extracting detailed bill information, sponsors, amendments, referrals, history, votes, and supplements. It combines results into a single list.
parse_bill_jsons <- function(json_paths){
parse_single_json  <- function(json_path) {
bill_data <- fromJSON(json_path, simplifyVector = FALSE)
bill <- bill_data$bill
# Extract flat information directly into a data frame
bill_info_df <- tibble(
number = bill$bill_number,
title = bill$title,
type = bill$bill_type,
bill_id = bill$bill_id,
description = bill$description,
session_id = bill$session$session_id,
session_name = bill$session$session_name,
year = bill$session$year_end
# Add more fields as needed
)
# Extract sponsors (assuming sponsors are a list of lists)
sponsors <- bind_rows(lapply(bill$sponsors, as_tibble), .id = bill$sponsor_id) %>%
mutate(bill_id = bill$bill_id) %>%
select(bill_id, everything())
amendments <- bind_rows(lapply(bill$amendments, as_tibble), .id = bill$amendment_id) %>%
mutate(bill_id = bill$bill_id) %>%
select(bill_id, everything())
referrals <- bind_rows(lapply(bill$referrals, as_tibble), .id = bill$committee_id) %>%
mutate(bill_id = bill$bill_id) %>%
select(bill_id, everything())
history <- bind_rows(lapply(bill$history, as_tibble)) %>%
mutate(bill_id = bill$bill_id) %>%
select(bill_id, everything())
votes <- bind_rows(lapply(bill$votes, as_tibble), .id = bill$roll_call_id) %>%
mutate(bill_id = bill$bill_id) %>%
select(bill_id, everything())
supplements <- bind_rows(lapply(bill$supplements, as_tibble), .id = bill$supplement_id) %>%
mutate(bill_id = bill$bill_id) %>%
select(bill_id, everything())
# Compile into a single list for this example
list(bill_info_df = bill_info_df,
sponsors = sponsors,
amendments = amendments,
supplements=supplements,
votes=votes,
history=history,
referrals=referrals)
}
pb <- progress::progress_bar$new(
format = "  Parsing bill details [:bar] :percent in :elapsed",
total = length(json_paths),
width = 60
)
parsed_results <- lapply(json_paths, function(path) {
pb$tick()
parse_single_json(path)
})
combined_results <- list(
sponsors <- bind_rows(lapply(bill$sponsors, as_tibble), .id = bill$sponsor_id),
bill_info_df = bind_rows(lapply(parsed_results, `[[`, "bill_info_df")),
#sponsors = bind_rows(lapply(parsed_results, `[[`, "sponsors")),
amendments = bind_rows(lapply(parsed_results, `[[`, "amendments")),
supplements = bind_rows(lapply(parsed_results, `[[`, "supplements")),
votes = bind_rows(lapply(parsed_results, `[[`, "votes")),
history = bind_rows(lapply(parsed_results, `[[`, "history")),
referrals = bind_rows(lapply(parsed_results, `[[`, "referrals"))
)
return(combined_results)
}
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/02_parse_legiscan.R", echo=TRUE)
View(bills_all)
View(bills_all)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/03_load_views.R", echo=TRUE)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/03_load_views.R", echo=TRUE)
names(heatmap_data)
column_info <- sapply(heatmap_data, function(x) {
type <- class(x)[1]
first_value <- ifelse(length(x) > 0, as.character(x[1]), NA)
paste("Type:", type, "First value:", first_value)
})
print(column_info)
column_info <- data.frame(
field_name = names(heatmap_data),
type = sapply(df, function(x) class(x)[1]),
sample_value = sapply(df, function(x) {
if (length(x) > 0) as.character(x[1]) else NA
}),
stringsAsFactors = FALSE
)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/document-architecture.R", echo=TRUE)
column_info <- getColumnInfo(heatmap_data)
document_heatmap <- getColumnInfo(heatmap_data)
write.csv(document_heatmap, file = "../diagrams/document_heatmap.csv", row.names = FALSE)
write.csv(document_heatmap, file = "diagrams/document_heatmap.csv", row.names = FALSE)
file.remove("column_info")
rm("column_info")
length(unique(bill_meta$bill_id))
table(bill_meta$bill_id, bill_meta$session_id)
print(combination_counts[combination_counts > 1])
length(unique(bill_meta$number))
unique(bill_meta$session_string)
unique(bill_meta$session_id)
unique(bill_meta$session_name)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/02_parse_legiscan.R", echo=TRUE)
library(tidyverse)  # A collection of R packages for data science
library(tidytext)   # Text mining using tidy data principles
library(legiscanrr) # Interface with the LegiScan API for accessing legislative data / devtools::install_github("fanghuiz/legiscanrr")
library(pscl)       # Political Science Computational Laboratory package for analyzing roll call data and IRT models
library(wnominate)  # W-NOMINATE package for scaling roll call data and estimating ideal points
library(oc)         # Optimal Classification package for scaling roll call data
library(dwnominate) # Dynamic Weighted NOMINATE for analyzing changes in voting patterns over time / remotes::install_github('wmay/dwnominate')
library(jsonlite)   # Tools for parsing, generating, and manipulating JSON data
library(SnowballC)  # Snowball stemmers for text preprocessing and stemming in natural language processing
library(future.apply)
#additional libraries for database interaction
library(DBI)
library(RPostgres)
library(progress) # to show progress bar during database write operations
library(dplyr) # allows excluding specific columns by name from sql commands (e.g. to debug heatmap_data)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/02_parse_legiscan.R", echo=TRUE)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/etl_main.R", echo=TRUE)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/03_load_views.R", echo=TRUE)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/04_transform.R", echo=TRUE)
file.copy("02_parse_legiscan.R", "BKP 2024-06-24 02_parse_legiscan.R")
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/02_parse_legiscan.R", echo=TRUE)
# create a dataframe for each bill-related table returned in parse_bills
bill_votes <- bills_parsed$votes
View(bill_votes)
View("bill_votes")
View("bills")
# create a dataframe for each bill-related table returned in parse_bills
bill_votes <- bills_parsed$votes
# Add session to bills dataframe based on pathname
bills <- bills_parsed$meta %>%
mutate(
session_year = as.numeric(str_extract(session_name, "\\d{4}")), # Extract year
two_year_period = case_when(
session_year < 2011 ~ "2010 or earlier",
session_year %% 2 == 0 ~ paste(session_year - 1, session_year, sep="-"),
TRUE ~ paste(session_year, session_year + 1, sep="-")
)
)
# parse bills json, storing related tables in a list of tables (meta, votes)
bills_parsed <- parse_bills(text_paths_bills)
# create a dataframe for each bill-related table returned in parse_bills
bill_votes <- bills_parsed$votes
# Add session to bills dataframe based on pathname
bills <- bills_parsed$meta %>%
mutate(
session_year = as.numeric(str_extract(session_name, "\\d{4}")), # Extract year
two_year_period = case_when(
session_year < 2011 ~ "2010 or earlier",
session_year %% 2 == 0 ~ paste(session_year - 1, session_year, sep="-"),
TRUE ~ paste(session_year, session_year + 1, sep="-")
)
)
str(bills_parsed)
bill_json_paths <- c("../data-raw/legiscan/2023-2024_Regular_Session/2023-2023_Regular_Session/H0001.json", "../data-raw/legiscan/2023-2024_Regular_Session/2023-2023_Regular_Session/H0003.json")
bills_parsed <- parse_bills(bill_json_paths)
bill_json_paths <- c("data-raw/legiscan/2023-2024_Regular_Session/2023-2023_Regular_Session/H0001.json", "data-raw/legiscan/2023-2024_Regular_Session/2023-2023_Regular_Session/H0003.json")
bills_parsed <- parse_bills(bill_json_paths)
file.copy("BKP 2024-06-24 02_parse_legiscan.R","02_parse_legiscan.R")
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/02_parse_legiscan.R", echo=TRUE)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/02_parse_legiscan.R", echo=TRUE)
# parse bills json, storing related tables in a list of tables (meta, progress, history, sponsors, sasts, texts)
bills_parsed <- parse_bills(text_paths_bills)
#Extracts bill metadata including session information, progress, history, sponsors, and other related attributes from given JSON file paths.
parse_bills <- function(bill_json_paths) {
pb <- progress::progress_bar$new(
format = "  parsing bill metadata [:bar] :percent in :elapsed.",
total = length(bill_json_paths), clear = FALSE, width = 60
)
extract_bill_meta <- function(input_bill_path) {
pb$tick()
session_regex <- "(\\d{4}-\\d{4}_[^/]+_Session)"
session_matches <- regexpr(session_regex, input_bill_path)
session_string <- ifelse(session_matches != -1, regmatches(input_bill_path, session_matches), NA)
bill_data <- jsonlite::fromJSON(input_bill_path, simplifyVector = FALSE)
bill <- bill_data$bill
# Handling missing fields with NA
number <- ifelse(is.null(bill$bill_number), NA, bill$bill_number)
bill_id <- ifelse(is.null(bill$bill_id), NA, bill$bill_id)
session_id <- ifelse(is.null(bill$session_id), NA, bill$session_id)
session_name <- ifelse(is.null(bill$session$session_name), NA, bill$session$session_name)
url <- ifelse(is.null(bill$url), NA, bill$url)
title <- ifelse(is.null(bill$title), NA, bill$title)
type <- ifelse(is.null(bill$type), NA, bill$type)
description <- ifelse(is.null(bill$description), NA, bill$description)
status <- ifelse(is.null(bill$status), NA, bill$status)
status_date <- ifelse(is.null(bill$status_date), NA, bill$status_date)
# parse related tables
votes_df <- extract_votes(bill$votes, bill_id)
df <- data.frame(
number = number,
bill_id = bill_id,
session_id = session_id,
session_string = session_string,
session_name = session_name,
url = url,
title = title,
type = type,
description = description,
status = status,
status_date = status_date,
stringsAsFactors = FALSE
)
return(list(meta = df, votes = votes_df))
}
output_list <- lapply(bill_json_paths, extract_bill_meta)
meta_df <- do.call(rbind, lapply(output_list, `[[`, "meta"))
votes_df <- do.call(rbind, lapply(output_list, `[[`, "votes"))
return(list(meta = meta_df, votes = votes_df))
}
# parse bills json, storing related tables in a list of tables (meta, progress, history, sponsors, sasts, texts)
bills_parsed <- parse_bills(text_paths_bills)
# create a dataframe for each bill-related table returned in parse_bills
bill_votes <- bills_parsed$votes
# Add detail to bills dataframe (meta)
bills <- bills_parsed$meta %>%
mutate(
session_year = as.numeric(str_extract(session_name, "\\d{4}")), # Extract year
two_year_period = case_when(
session_year < 2011 ~ "2010 or earlier",
session_year %% 2 == 0 ~ paste(session_year - 1, session_year, sep="-"),
TRUE ~ paste(session_year, session_year + 1, sep="-")
)
)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/03_load_views.R", echo=TRUE)
source("C:/Users/relia/jour/my_database_projects/fl-legislation-db/scripts/04_transform.R", echo=TRUE)
rlang::last_trace()
rlang::last_trace(drop = FALSE)
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/etl_main.R", echo=TRUE)
View(legislator_history)
legislator_sessions <- legislator_history
rm(legislator_history)
output_df
#adds "session" field (e.g. "2023-2024_Regular_Session") based on file pathname
parse_legislator_sessions <- function (people_json_paths) {
#initialize progress bar
pb <- progress::progress_bar$new(format = "  parsing_legislator sessions [:bar] :percent in :elapsed.",
total = length(people_json_paths), clear = FALSE, width = 60)
pb$tick(0)
# helper function: for each JSON file path, update the progress bar, determine session info from pathname, read JSON file
extract_people_meta <- function(input_people_json_path) {
pb$tick()
# Define a regex to match the session pattern in the file path
session_regex <- "(\\d{4}-\\d{4}_[^/]+_Session)"
# Extract session from the file path using the defined regex
matches <- regmatches(input_people_json_path, regexpr(session_regex, input_people_json_path))
session_info <- ifelse(length(matches) > 0, matches, NA)
input_people_json <- jsonlite::fromJSON(input_people_json_path)
people_meta <- input_people_json[["person"]]
# Append session info as a new column
people_meta$session <- session_info
people_meta # return people_meta
}
# run extract_people_meta for each file, combine results into output_df, then return output_df
output_list <- lapply(people_json_paths, extract_people_meta)
output_df <- data.table::rbindlist(output_list, fill = TRUE)
output_df <- tibble::as_tibble(data.table::setDF(output_df))
#test this function
print("check duplicate rows")
duplicated_rows <- output_df[duplicated(output_df), ]
print(duplicated_rows)
print("check unique sessions")
unique_sessions <- unique(output_df$session)
print(unique_sessions)
unique_paths <- unique(people_json_paths)
if (length(unique_paths) != length(people_json_paths)) {
print("Duplicate paths detected")
}
output_df # return output_df
}
legislator_sessions <- parse_legislator_sessions(text_paths_leg) #adds session ID to potentially reflect changing roles
################################
#                              #
# 0) for testing only          #
#                              #
################################
#set working directory to the location of current script
setwd(script_dir <- dirname(rstudioapi::getActiveDocumentContext()$path))
#adds "session" field (e.g. "2023-2024_Regular_Session") based on file pathname
parse_legislator_sessions <- function (people_json_paths) {
#initialize progress bar
pb <- progress::progress_bar$new(format = "  parsing_legislator sessions [:bar] :percent in :elapsed.",
total = length(people_json_paths), clear = FALSE, width = 60)
pb$tick(0)
# helper function: for each JSON file path, update the progress bar, determine session info from pathname, read JSON file
extract_people_meta <- function(input_people_json_path) {
pb$tick()
# Define a regex to match the session pattern in the file path
session_regex <- "(\\d{4}-\\d{4}_[^/]+_Session)"
# Extract session from the file path using the defined regex
matches <- regmatches(input_people_json_path, regexpr(session_regex, input_people_json_path))
session_info <- ifelse(length(matches) > 0, matches, NA)
input_people_json <- jsonlite::fromJSON(input_people_json_path)
people_meta <- input_people_json[["person"]]
# Append session info as a new column
people_meta$session <- session_info
people_meta # return people_meta
}
# run extract_people_meta for each file, combine results into output_df, then return output_df
output_list <- lapply(people_json_paths, extract_people_meta)
output_df <- data.table::rbindlist(output_list, fill = TRUE)
output_df <- tibble::as_tibble(data.table::setDF(output_df))
#test this function
print("check duplicate rows")
duplicated_rows <- output_df[duplicated(output_df), ]
print(duplicated_rows)
print("check unique sessions")
unique_sessions <- unique(output_df$session)
print(unique_sessions)
unique_paths <- unique(people_json_paths)
if (length(unique_paths) != length(people_json_paths)) {
print("Duplicate paths detected")
}
output_df # return output_df
}
# For now, only working with folder data-raw/legiscan/2023-2024_Regular_Session
# to look at all years, work with 2010-2024-all
text_paths_votes <- find_json_path(base_dir = "../data-raw/legiscan/2023-2024_Regular_Session/..", file_type = "vote")
text_paths_bills <- find_json_path(base_dir = "../data-raw/legiscan/2023-2024_Regular_Session/..", file_type = "bill")
text_paths_legislators <- find_json_path(base_dir = "../data-raw/legiscan/2023-2024_Regular_Session/..",file_type = "people")
legislator_sessions <- parse_legislator_sessions(text_paths_legislators) #adds session ID to potentially reflect changing roles
#adds "session" field (e.g. "2023-2024_Regular_Session") based on file pathname
parse_legislator_sessions <- function (people_json_paths) {
#initialize progress bar
pb <- progress::progress_bar$new(format = "  parsing_legislator sessions [:bar] :percent in :elapsed.",
total = length(people_json_paths), clear = FALSE, width = 60)
pb$tick(0)
# helper function: for each JSON file path, update the progress bar, determine session info from pathname, read JSON file
extract_people_meta <- function(input_people_json_path) {
pb$tick()
# Extract session info from file path using a defined regex
session_regex <- "(\\d{4}-\\d{4}_[^/]+_Session)"
matches <- regmatches(input_people_json_path, regexpr(session_regex, input_people_json_path))
session_info <- ifelse(length(matches) > 0, matches, NA)
input_people_json <- jsonlite::fromJSON(input_people_json_path)
people_meta <- input_people_json[["person"]]
# Append session info as a new column
people_meta$session <- session_info
people_meta # return people_meta
}
# run extract_people_meta for each file, combine results into output_df, then return output_df
output_list <- lapply(people_json_paths, extract_people_meta)
output_df <- data.table::rbindlist(output_list, fill = TRUE)
output_df <- tibble::as_tibble(data.table::setDF(output_df))
#test this function
print("check duplicate rows")
duplicated_rows <- output_df[duplicated(output_df), ]
print(duplicated_rows)
output_df <- distinct(output_df)
nrow(output_df)  # Should be close to 434, the expected number
# print("check unique sessions")
# unique_sessions <- unique(output_df$session)
# print(unique_sessions)
# unique_paths <- unique(people_json_paths)
# if (length(unique_paths) != length(people_json_paths)) {
#   print("Duplicate paths detected")
# }
output_df # return output_df
}
print(text_paths_legislators)
legislator_sessions <- parse_legislator_sessions(text_paths_legislators) #adds session ID to potentially reflect changing roles
#######################################################################################
#unpacks Legiscan's ls_bill_vote_detail from JSON into a dataframe
#adds "session" field (e.g. "2023-2024_Regular_Session") based on file pathname
#?adds "roll call id" for each vote record?
#?? Extracts vote information and session details from JSON file paths.
parse_legislator_votes <- function (vote_json_paths) {
pb <- progress::progress_bar$new(format = "  parsing legislator_votes [:bar] :percent in :elapsed.",
total = length(vote_json_paths), clear = FALSE, width = 60)
pb$tick(0)
extract_vote <- function(input_vote_json_path) {
pb$tick()
# Extract session from the file path
session_regex <- "(\\d{4}-\\d{4}_[^/]+_Session)"
session_info <- regmatches(input_vote_json_path, regexpr(session_regex, input_vote_json_path))
input_vote <- jsonlite::fromJSON(input_vote_json_path)
input_vote <- input_vote[["roll_call"]]
person_vote <- input_vote[["votes"]]
person_vote$roll_call_id <- input_vote[["roll_call_id"]]
# Append session info as a new column
person_vote$session <- session_info
person_vote
}
output_list <- lapply(vote_json_paths, extract_vote)
output_df <- data.table::rbindlist(output_list, fill = TRUE)
output_df <- tibble::as_tibble(data.table::setDF(output_df))
output_df
}
length(text_paths_legislators)
# For now, only working with folder data-raw/legiscan/2023-2024_Regular_Session
# to look at all years, work with 2010-2024-all
base_dir <- "../data-raw/legiscan/2023-2024_Regular_Session/"
# text_paths_votes <- find_json_path(base_dir = "../data-raw/legiscan/2023-2024_Regular_Session/..", file_type = "vote")
# text_paths_bills <- find_json_path(base_dir = "../data-raw/legiscan/2023-2024_Regular_Session/..", file_type = "bill")
# text_paths_legislators <- find_json_path(base_dir = "../data-raw/legiscan/2023-2024_Regular_Session/..",file_type = "people")
text_paths_legislators <- list.files(path = base_dir, pattern = "\\.json$", full.names = TRUE, recursive = TRUE)
# Check the number of files found
number_of_files <- length(text_paths_legislators)
print(number_of_files)
# Use list.files to find all JSON files in the base directory and its subdirectories
all_json_paths <- list.files(path = base_dir, pattern = "\\.json$", full.names = TRUE, recursive = TRUE)
# Filter paths to include only those within "people" directories
text_paths_legislators <- all_json_paths[grepl("/people/", all_json_paths, ignore.case = TRUE)]
# Check the number of files found
number_of_files <- length(text_paths_legislators)
print(number_of_files)
# For now, only working with folder data-raw/legiscan/2023-2024_Regular_Session
# to look at all years, work with 2010-2024-all
base_dir <- "../data-raw/legiscan/2023-2024_Regular_Session/"
all_json_paths <- list.files(path = base_dir, pattern = "\\.json$", full.names = TRUE, recursive = TRUE)
text_paths_bills <- all_json_paths[grepl("/bill/", all_json_paths, ignore.case = TRUE)]
text_paths_legislators <- all_json_paths[grepl("/people/", all_json_paths, ignore.case = TRUE)]
text_paths_votes <- all_json_paths[grepl("/vote/", all_json_paths, ignore.case = TRUE)]
# Check the number of files found
n_bills <- length(text_paths_bills)
n_legislators <- length(text_paths_legislators)
n_votes <- length(text_paths_votes)
all_json_paths <- list.files(path = base_dir, pattern = "\\.json$", full.names = TRUE, recursive = TRUE)
text_paths_bills <- all_json_paths[grepl("/bill/", all_json_paths, ignore.case = TRUE)]
text_paths_legislators <- all_json_paths[grepl("/people/", all_json_paths, ignore.case = TRUE)]
text_paths_votes <- all_json_paths[grepl("/vote/", all_json_paths, ignore.case = TRUE)]
# Check the number of files found
n_bills <- length(text_paths_bills)
n_legislators <- length(text_paths_legislators)
n_votes <- length(text_paths_votes)
print(paste0("# of bill-sessions: ",n_bills)
print(paste0("# of votes: ",n_votes)
print(paste0("# of bill-sessions: ",n_bills))
print(paste0("# of legislator-sessions: ",n_legislators))
print(paste0("# of votes: ",n_votes))
legislator_sessions <- parse_legislator_sessions(text_paths_legislators) #adds session ID to potentially reflect changing roles
# For now, only working with folder data-raw/legiscan/2023-2024
# to look at all years, work with 2010-2024
base_dir <- "../data-raw/legiscan/2023-2024/"
all_json_paths <- list.files(path = base_dir, pattern = "\\.json$", full.names = TRUE, recursive = TRUE)
text_paths_bills <- all_json_paths[grepl("/bill/", all_json_paths, ignore.case = TRUE)]
text_paths_legislators <- all_json_paths[grepl("/people/", all_json_paths, ignore.case = TRUE)]
text_paths_votes <- all_json_paths[grepl("/vote/", all_json_paths, ignore.case = TRUE)]
# Check the number of files found
n_bills <- length(text_paths_bills)
n_legislators <- length(text_paths_legislators)
n_votes <- length(text_paths_votes)
print(paste0("# of bill-sessions: ",n_bills))
print(paste0("# of legislator-sessions: ",n_legislators))
print(paste0("# of votes: ",n_votes))
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/02_parse_legiscan.R", echo=TRUE)
rm(list = ls())
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/etl_main.R", echo=TRUE)
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/functions_database.R", echo=TRUE)
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/03_load_views.R", echo=TRUE)
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/functions_database.R", echo=TRUE)
source("C:/Users/relia/jour/jaxtrib/fl-leg-etl/scripts/03_load_views.R", echo=TRUE)
# trying to get rid of bill_detailed
# votes_all <- left_join(bill_detailed$votes,bill_detailed$bill_info_df) %>% mutate(pct = yea/total)
votes_all <- left_join(bill_votes,bills) %>% mutate(pct = yea/total)
View(votes_all)
